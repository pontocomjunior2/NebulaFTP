from asyncio import CancelledError, get_event_loop, gather, sleep as asleep
from collections import namedtuple
from functools import wraps
from io import BytesIO
from pathlib import PurePosixPath
from sys import exc_info
from time import time
from uuid import uuid4
import os
import aiofiles
import logging

from .errors import PathIOError
from .tg import File
from .common import UPLOAD_QUEUE

# Usa o logger configurado no main.py
logger = logging.getLogger("NebulaFTP")

__all__ = ("AbstractPathIO", "PathIONursery", "MongoDBPathIO")

CACHE_DIR = "staging"
if not os.path.exists(CACHE_DIR): os.makedirs(CACHE_DIR)

def universal_exception(coro):
    @wraps(coro)
    async def wrapper(*args, **kwargs):
        try:
            return await coro(*args, **kwargs)
        except (CancelledError, NotImplementedError, StopAsyncIteration):
            raise
        except Exception as exc:
            raise PathIOError(reason=exc_info()) from exc
    return wrapper

class PathIONursery:
    def __init__(self, factory):
        self.factory = factory
        self.state = None
    def __call__(self, *args, **kwargs):
        instance = self.factory(*args, state=self.state, **kwargs)
        if self.state is None: self.state = instance.state
        return instance

class AbstractPathIO:
    def __init__(self, connection=None):
        self.connection = connection

class Node:
    def __init__(self, type, name, ctime=None, mtime=None, size=0, parent="/", parts=None, **k):
        if parts is None: parts = []
        self.type = type; self.name = name
        self.ctime = ctime or int(time()); self.mtime = mtime or int(time())
        self.size = size; self.parent = parent
        self.path = str(PurePosixPath(parent) / name); self.parts = parts

class MongoDBMemoryIO:
    def __init__(self, node, mode, tg, db):
        self._node = node; self._mode = mode; self._tg = tg; self._db = db
        self.offset = 0
        safe_name = f"{uuid4().hex}_{node.name}"
        self.local_path = os.path.join(CACHE_DIR, safe_name)

    async def __aenter__(self): return self
    async def __aexit__(self, *args, **kwargs): pass
    async def seek(self, offset=0): self.offset = offset

    async def write_stream(self, stream):
        logger.info(f"ðŸ“¥ [FTP] Recebendo: {self._node.name}")
        async with aiofiles.open(self.local_path, "wb") as f:
            if self.offset > 0: await f.seek(self.offset)
            async for data in stream.iter_by_block(1024*1024):
                await f.write(data)
            await f.flush()
        
        final_size = os.path.getsize(self.local_path)
        if final_size == 0: return

        logger.info(f"ðŸ’¾ [FTP] Salvo em Disco: {self._node.name} ({final_size} B)")
        
        # Gera ID de upload para rastreamento no DB (facilita Ã­ndices)
        upload_id = uuid4().hex
        
        # Atualiza o documento no banco para marcar que o upload fÃ­sico comeÃ§ou
        await self._db.files.update_one(
            {"name": self._node.name, "parent": str(self._node.parent)},
            {"$set": {"uploadId": upload_id}}
        )

        await UPLOAD_QUEUE.put({
            "path": self.local_path,
            "filename": self._node.name,
            "parent": str(self._node.parent),
            "size": final_size
        })

    def _chunks(self, lst, n):
        for i in range(0, len(lst), n): yield lst[i:i + n]

    async def iter_by_block(self, block_size):
        # LÃ³gica Smart Seek mantida (essencial para leitura)
        loop = get_event_loop()
        parts = self._node.parts
        parts.sort(key=lambda x: x["part_id"])
        current_file_pos = 0
        start_read_at = self.offset
        
        for part in parts:
            part_size = part.get("file_size", 0)
            if part_size == 0: part_size = 2 * 1024 * 1024 * 1024 
            part_end = current_file_pos + part_size
            
            if part_end <= start_read_at:
                current_file_pos += part_size; continue
            
            local_offset = max(0, start_read_at - current_file_pos)
            file = File(part["tg_file"], self._tg)
            async for chunk in file.stream(offset=local_offset): yield chunk
            
            current_file_pos += part_size
            start_read_at = current_file_pos

class MongoDBPathIO(AbstractPathIO):
    db = None; tg = None
    Stats = namedtuple("Stats", ("st_size", "st_ctime", "st_mtime", "st_nlink", "st_mode"))

    def __init__(self, *args, state=None, cwd=None, **kwargs):
        super().__init__(*args, **kwargs); self.cwd = PurePosixPath("/")

    @property
    def state(self): return []
    def _absolute(self, path):
        if not path.is_absolute(): path = self.cwd / path
        return path

    async def get_node(self, path):
        if str(path) == "/": return Node("dir", "", 0, 0, size=0, parent="/")
        node = await self.db.files.find_one({"name": path.parts[-1], "parent": str(path.parents[0])})
        return Node(**node) if node else None

    @universal_exception
    async def exists(self, path): return (await self.get_node(self._absolute(path))) is not None

    @universal_exception
    async def is_dir(self, path):
        node = await self.get_node(self._absolute(path))
        return not (node is None or node.type != "dir")

    @universal_exception
    async def is_file(self, path):
        node = await self.get_node(self._absolute(path))
        return not (node is None or node.type != "file")

    @universal_exception
    async def mkdir(self, path, *, exist_ok=False):
        path = self._absolute(path)
        if await self.get_node(path):
            if not exist_ok: raise FileExistsError
        else:
            # Upsert para garantir seguranÃ§a contra race conditions
            try:
                await self.db.files.insert_one({
                    "type": "dir", "ctime": int(time()), "mtime": int(time()),
                    "name": path.parts[-1], "parent": str(path.parents[0]), "size": 0
                })
            except Exception:
                if not exist_ok: raise FileExistsError

    @universal_exception
    async def rmdir(self, path):
        path = self._absolute(path)
        await self.db.files.delete_one({"name": path.parts[-1], "parent": str(path.parents[0])})
        await self.db.files.delete_many({"parent": str(path)})

    @universal_exception
    async def unlink(self, path):
        path = self._absolute(path)
        await self.db.files.delete_one({"name": path.parts[-1], "parent": str(path.parents[0])})

    def list(self, path):
        path = self._absolute(path)
        class Lister:
            iter = None
            def __aiter__(self): return self
            @universal_exception
            async def __anext__(cls):
                if cls.iter is None:
                    cls.iter = self.db.files.find({"parent": str(path)})
                try: return path / (await cls.iter.__anext__())["name"]
                except StopAsyncIteration: raise
        return Lister()

    @universal_exception
    async def stat(self, path):
        node = await self.get_node(self._absolute(path))
        if node is None: raise FileNotFoundError
        mode = (0x8000 | 0o666) if node.type == "file" else (0x4000 | 0o777)
        return MongoDBPathIO.Stats(node.size, node.ctime, node.mtime, 1, mode)

    @universal_exception
    async def open(self, path, mode="rb", *args, **kwargs):
        path = self._absolute(path)
        if mode == "wb":
            # Uso de update_one com upsert=True evita race conditions e limpa dados antigos
            await self.db.files.update_one(
                {"name": path.parts[-1], "parent": str(path.parents[0])},
                {"$set": {
                    "type": "file", "ctime": int(time()), "mtime": int(time()),
                    "size": 0, "parts": []
                }},
                upsert=True
            )
        
        node = await self.get_node(path)
        if not node and mode == "rb": raise FileNotFoundError
        return MongoDBMemoryIO(node, mode, self.tg, self.db)

    @universal_exception
    async def rename(self, source, destination):
        source = self._absolute(source); destination = self._absolute(destination)
        if source != destination:
            await self.db.files.update_one(
                {"name": source.parts[-1], "parent": str(source.parents[0])},
                {"$set": {"name": destination.parts[-1], "parent": str(destination.parents[0]), "ctime": int(time())}}
            )
